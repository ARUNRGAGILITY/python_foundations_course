# Python Deep Learning

Deep Learning is a subfield of machine learning that focuses on neural networks with multiple layers (deep neural networks) to model and solve complex problems. It has gained immense popularity in recent years due to its ability to automatically learn hierarchical features from data, making it particularly powerful in tasks such as image recognition, natural language processing, and autonomous driving. Here's an introduction to Deep Learning along with code examples:

### Key Concepts in Deep Learning:

1. **Neural Networks**: Deep Learning is based on artificial neural networks, which are inspired by the structure and function of the human brain. A neural network consists of interconnected layers of neurons (units).

2. **Deep Neural Networks (DNNs)**: DNNs have multiple hidden layers between the input and output layers. These layers enable the network to learn complex representations of data.

3. **Activation Functions**: Activation functions introduce non-linearity into neural networks, allowing them to model complex relationships. Common activation functions include ReLU (Rectified Linear Unit) and Sigmoid.

4. **Backpropagation**: Training deep neural networks involves a process called backpropagation, where the model adjusts its weights and biases to minimize the prediction error (loss) on the training data.

5. **Convolutional Neural Networks (CNNs)**: CNNs are specialized deep neural networks designed for processing grid-like data, such as images. They use convolutional layers to automatically detect features.

6. **Recurrent Neural Networks (RNNs)**: RNNs are used for sequential data, such as text or time series. They have loops that allow information to persist from previous time steps.

### Deep Learning in Python:

Python is the primary programming language for Deep Learning due to its extensive libraries and frameworks. Here's an overview of Deep Learning in Python with code examples:

#### Image Classification with Convolutional Neural Networks (CNNs):

```python
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

# Load the CIFAR-10 dataset
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Preprocess the data
train_images, test_images = train_images / 255.0, test_images / 255.0

# Create a CNN model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10)
])

# Compile the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Train the model
history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))

# Plot training history
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()
```

#### Natural Language Processing (NLP) with Recurrent Neural Networks (RNNs):

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Sample text data
texts = ["I love deep learning", "Deep learning is fascinating", "Neural networks are powerful"]

# Tokenize and pad sequences
tokenizer = Tokenizer(num_words=100, oov_token="<OOV>")
tokenizer.fit_on_texts(texts)
sequences = tokenizer.texts_to_sequences(texts)
padded_sequences = pad_sequences(sequences, maxlen=6, padding='post', truncating='post')

# Create an LSTM-based model
model = keras.Sequential([
    Embedding(input_dim=100, output_dim=16, input_length=6),
    LSTM(32),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
```

These examples demonstrate Deep Learning applications for image classification and natural language processing. Deep Learning libraries like TensorFlow and PyTorch provide a wide range of tools and models for various tasks, allowing developers to build powerful neural networks for real-world problems.
